# Concerns Regarding Unfair Grading Practices for TDS Project 2


---

**22f3002811** on 2024-12-27:

Dear Tds team , @andrew @Bharathi @Milo ,
I am writing to express my concerns regarding the evaluation of Project 2 for the TDS course. Several aspects of the grading process have raised serious issues of fairness, transparency, and academic integrity, which are causing undue stress among students.
Firstly, the evaluation matrices appear to be biased and disproportionately harsh. For instance, even scripts that scored as high as 89 in visible test cases were unable to solve the hidden cases, with no explanation provided for the failure. This lack of feedback makes it impossible for students to understand or address their mistakes, leading to significant frustration.
Additionally, the overall scores do not seem to accurately reflect the quality or efficiency of the submitted scripts. Many students have put in substantial effort to write optimized and functional code, only to receive grades that undermine their hard work. The lack of transparency in how the final grades are determined further exacerbates this issue.
This project’s grading has had an outsized impact on the overall course grade, jeopardizing the academic standing of many students. Such a disproportionate weight on one project, coupled with an unusually high level of complexity this term, has made it exceedingly difficult for students to achieve even a decent grade. This has resulted in feelings of humiliation and distress.
I kindly request that the department reviews the evaluation process for Project 2, providing greater transparency in scoring, a more balanced weighting for grades, and constructive feedback on hidden test cases. This would ensure a fairer assessment of students’ efforts and capabilities.
I hope you will consider the concerns raised here and take the necessary steps to rectify the situation. I, along with my peers, am willing to discuss this matter further if required.
Thank you for your understanding.
Sincerely,
Aditya Gupta
TDS Course Participant

[Source](https://discourse.onlinedegree.iitm.ac.in/t/concerns-regarding-unfair-grading-practices-for-tds-project-2/160611/1)

---

**22f3002293** on 2024-12-27:

If its unfair, its unfair for all right, so whats the point in bringing this up. You should tell if these practices have given unfair advantage to someone, then only it makes some sense.
I agree that the grading of TDS was harsh, but then it is for everyone, you are not singled out right.
Please correct me if i am wrong.

[Source](https://discourse.onlinedegree.iitm.ac.in/t/concerns-regarding-unfair-grading-practices-for-tds-project-2/160611/2)

---

**23f2005059** on 2024-12-27:

Yes it is unfair for all people who took tds this term, all those who took before sep24 and after sep24 will have an unfair gpa advantage, whereas we are loosing 2 grade points very unfairly.
As it should be said:
Proj2 uses concepts which are not explicitly it’s prerequisites.
Even after following instructions properly and giving time, a good score is IMPOSSIBLE.
The instructor himself can’t make a proj that can get a good score consistently after multiple runs

[Source](https://discourse.onlinedegree.iitm.ac.in/t/concerns-regarding-unfair-grading-practices-for-tds-project-2/160611/3)

---

**22f3002293** on 2024-12-27:




 23f2005059:

Yes it is unfair for all people who took tds this term


So, people who took TDS in this term, including me, have to live with it, there is no other option.

[Source](https://discourse.onlinedegree.iitm.ac.in/t/concerns-regarding-unfair-grading-practices-for-tds-project-2/160611/4)

---

**23f2005059** on 2024-12-27:

Your reply aptly encapsulates the hopelessness the course team has bestowed upon us. Atleast now they should change the grading weightage or put relative grading

[Source](https://discourse.onlinedegree.iitm.ac.in/t/concerns-regarding-unfair-grading-practices-for-tds-project-2/160611/5)

---

**22f3002293** on 2024-12-27:




 23f2005059:

Your reply aptly encapsulates the hopelessness the course team has bestowed upon us


So true



 23f2005059:

Atleast now they should change the grading weightage or put relative grading


I hope they will change

[Source](https://discourse.onlinedegree.iitm.ac.in/t/concerns-regarding-unfair-grading-practices-for-tds-project-2/160611/6)

---

**Devanathan** on 2024-12-27:

The grading is absolute so everyone is at loss, simple logic. If relative grading would have been there then there was no issue, as simple as that!

[Source](https://discourse.onlinedegree.iitm.ac.in/t/concerns-regarding-unfair-grading-practices-for-tds-project-2/160611/7)

---

**Devanathan** on 2024-12-27:

True, the project 2 scoring is too hazy, I got 14/14 in evaluation and 35 overall, so why was that evaluation script provided to us! Like the course is to teach hs, how do you expect us to know everything before hand, then why would anyone take this course! We should just go to youtube and watch the videos!!

[Source](https://discourse.onlinedegree.iitm.ac.in/t/concerns-regarding-unfair-grading-practices-for-tds-project-2/160611/8)

---

**jkmadathil** on 2024-12-27:




 22f3002811:

Several aspects of the grading process have raised serious issues of fairness, transparency, and academic integrity, which are causing undue stress among students.


It would be good to know what part of evaluation was not transparent. From what I have seen of the project, the problem statement, evaluation criteria and best practices were explained very clearly right from the start. Please check the github page for the evaluation criteria.
Now specifically if I take your submission and check for what went wrong (use this link to see the detail) In fact I would say that the faculty has been more transparent in revealing results of each student with greater details.


Explanation given by Carlton in another thread
EDIT:
If you want to see the alignment, please check the reply that @carlton gave in a separate thread.




 22f3002811:

the evaluation matrices appear to be biased and disproportionately harsh.


I do understand that the evaluating matrices are hard/tough, but if you actually look at the skill sets being assessed, we are looking at:

Data Analysis skill sets
Deployability skill sets
Presentation skill sets
Prompt Engineering skill sets

I believe the materials that you have seen in the course in this term actually covers all these skill sets sufficiently to prepare you for the assessments. By any chance did you attend the TA session for Project 2? There were a lot of helpful pointers that were discussed by @carlton and @Jivraj
If I am not mistaken, there was also an extension to the due date so that it gives learners sufficient time to try out various solution approaches.
Again, in terms of support both the faculty and TAs were consistently responding to major queries in the forum and were also updating the FAQs when they encounter same type of query.



 23f2005059:

Proj2 uses concepts which are not explicitly it’s prerequisites.


I believe the Project primarily needs the following skill sets:

Python
Git
LLMs - Specifically the function calls and chat completions, both of which were detailed in the module

The only new knowledge that you need were on UV, for which the videos were provided along with the Project 2 statement. But even here there were sufficient support through the TA session and responses to the queries.
From an administrative point of view, this project actually introduces you to the kind of problems that you might face when you are in a Data Science firm or when you are doing a real-life Data Science problem. And these are the skill sets that will help you to prove your credentials.
Even if you look at the scores obtained by your peers, you can see that there are students who have done well in the project. Below is the distribution of scores:
Histogram of P2 Score frequncies600×371 10.3 KB
[This is very much in line with the typical curves that we get for Maths2 or Stats2 exams]



 22f3002293:

So, people who took TDS in this term, including me, have to live with it,


I believe every course is in its constant mode of improvement, and this is done so that the outcome aligns well with the learning goals set up for the course. Tools in Data Science is no exception, in fact this course that has to keep up with the changing landscape of tool usage and practices in the Industry, especially now that we see a greater focus among companies to hire students with skill sets that are tested in this project.
However, if you are still doubtful of transparency part of the project, please do comment. In fact we could even open up a meet to listen to your concerns and see if we are able to address them.

[Source](https://discourse.onlinedegree.iitm.ac.in/t/concerns-regarding-unfair-grading-practices-for-tds-project-2/160611/9)

---

**22f3002811** on 2024-12-27:

Thank you for your response to my earlier concerns. However, there are several points that remain unresolved, and I would appreciate further clarification and transparency on the following:

Use of AI for Grading:
Relying on AI for grading is inherently unfair, as manual evaluation and AI evaluation can produce significantly different results. Without a clear explanation of the AI’s decision-making process, it is impossible to trust the fairness of the scores.
Evaluation Script Issues:
The evaluation script seems to be flawed. For instance, even scripts scoring 14/14 in visible test cases end up receiving lower marks in the final evaluation. Additionally, the absence of any feedback mechanism renders the evaluation script practically useless. This lack of feedback also negates the value of live sessions since we cannot test the methods taught or determine which method is best for solving the problem.
Confusing and Inconsistent Result Display:
The result page is confusing and inconsistent with the dashboard. The histogram graph appears unreliable, and the detailed results section is incomplete—my roll number, for example, is missing entirely from this section, making it impossible to validate claims about a “detailed result.” I request access to the code or methodology used for generating these results to understand the process better.
Deadline Management:
While an extension of the due date was granted, it was irrelevant given the already overwhelming number of submissions due on December 15. Additionally, the delayed release of the project closer to the end-term added unnecessary pressure on students, which was unfair and could have been avoided with better planning.

These issues raise serious questions about the fairness, transparency, and effectiveness of the evaluation process. I kindly request you address these concerns and provide a detailed explanation or take corrective measures to ensure a fair and transparent grading system.
The matter is not that we did not understand the grading system , the issue is that the entire grading system is unfair by it’s design as the results it produce is not consistent.
Thank you for your time and attention to this matter.

[Source](https://discourse.onlinedegree.iitm.ac.in/t/concerns-regarding-unfair-grading-practices-for-tds-project-2/160611/10)

---

**22f3002811** on 2024-12-27:




 jkmadathil:

I believe the Project primarily needs the following skill sets:

Python
Git
LLMs - Specifically the function calls and chat completions, both of which were detailed in the module



While the skills you mentioned are indeed part of the project, the issue at hand is not about what this project tests but about what it represents.
As you are likely aware, this course carries the weightage of 3 credits and is designed to provide students with a brief overview of the tools used in data science. Given this, there is no reason to overly complicate a project that accounts for only 20% of the total grade.
The decision to make the final project unnecessarily complex—especially so close to the end-term submissions—is both bizarre and irresponsible. Students are already juggling multiple obligations, including OPPEs and vivas for other projects. This approach suggests a failure to consider the grading system’s purpose and value.
A balanced evaluation should aim to assess students’ understanding of the concepts taught, not overwhelm them with disproportionately difficult requirements. I urge you to reflect on this and consider whether such complexity aligns with the goals of this course.

[Source](https://discourse.onlinedegree.iitm.ac.in/t/concerns-regarding-unfair-grading-practices-for-tds-project-2/160611/11)

---

**jkmadathil** on 2024-12-27:

I am noting down my response to your concerns in the below post. @s.anand has publicly addressed some of these in his blog post
So you can read both our interpretations and take a call on whether you have received answers to all the concerns raised.



 22f3002811:

Use of AI for Grading:
Relying on AI for grading is inherently unfair, as manual evaluation and AI evaluation can produce significantly different results. Without a clear explanation of the AI’s decision-making process, it is impossible to trust the fairness of the scores.


While I agree that AI is unreliable, but I believe this was made explicit right from the release of the problem statement itself that the reviewer will be an LLM. So this should not have been the time to raise this concern.



 22f3002811:

For instance, even scripts scoring 14/14 in visible test cases end up receiving lower marks in the final evaluation.


I think it was very well explained that the evaluation script just does a sanity check and is not the final word when it comes to final evaluation.



 22f3002811:

Additionally, the absence of any feedback mechanism renders the evaluation script practically useless. This lack of feedback also negates the value of live sessions since we cannot test the methods taught or determine which method is best for solving the problem


While I agree to the feedback related portion, I have this basic question. The AI token were shared with you to test out the code. Wouldn’t you be able to get response from the LLM during the testing phase and get a response from it directly? I believe they didn’t change the model significantly during the evaluation period, so there should not be too many variations to the response.
Again, I’m not sure how this affects the value of live session. The Live sessions are kept so that any type of question can get addressed and is independent of whether you attempted the assignment or not. And I believe the forum was open for anyone to use, if in doubt, as I see both @carlton and @Jivraj answering most queries here. In fact Anand was also active in the P2 discussion thread clarifying the queries.



 22f3002811:

The result page is confusing and inconsistent with the dashboard.


I am totally with you here. But it is not hard to figure out. Let me break it down for you taking your case as an example. I followed the same process to understand the scoring process.
Screen 1: Results student wise
Result student wise1499×837 61.4 KB
The first thing to do is to search for your roll no (Simple Ctrl/Cmd+F) should suffice here.
Screen 2:
searching given rollno1043×748 60.8 KB
And when you click on your roll no id, you can see two things:


Only your results are seen
individual student result931×207 10.8 KB
The way I interpreted it was: You have scored 8.88 marks out of a total 28 marks that is possible, and the marks are based on 34 correct tests out of a possible 89.
Personal observations: The bar was deceiving (need to check what the div element was) and presence of legends would have made interpretation easier.


The URL changes for the selection

i.e. for any student to directly check their results they can use https://sanand0.github.io/tds-2024-sep-project-2-results/#?id=<RollNo>


This direct URL would have made life a lot easier for all students. Definitely a feedback that I will be giving Anand.
Screen 3: To check if my interpretation is correct, I clicked on the test tab now.
And lo and behold I see detailed evaluation of 89 test cases (direct url in case you want to check).
Tests tab1188×853 63.8 KB
Screen 4: Now that I have seen the test results, the next question was will the student know why their code failed in the test cases?? And to answer this click on the details tab and there you have details of each and every test along with the feedback.
Details of test results1657×808 116 KB
Hopefully, by now you would have figured out the direct URL for this.
As a complete outsider to the Project 2 implementation, it took me 5 minutes to figure this out, but the results.csv that Anand had shared in P2 thread helped a lot in interpretation and consolidation. But again, this was available along with result declaration.



 22f3002811:

I request access to the code or methodology used for generating these results to understand the process better.


If I am not mistaken, the evaluation script is already shared with all of you much well in advance (even before due date). This is the same that you used in your local evaluation. The only difference, if I understood the process correctly, is that it now run on a different server for the actual evaluation.



 22f3002811:

it was irrelevant given the already overwhelming number of submissions due on December 15. Additionally, the delayed release of the project closer to the end-term added unnecessary pressure on students, which was unfair and could have been avoided with better planning.


As an administrator, I will concur with one part of your grievance that the project release could have been planned a little better so that it did not end a week before the End terms. But having said that, I guess the team would have intimated you about the new dates well in advance during the term itself.



 22f3002811:

As you are likely aware, this course carries the weightage of 3 credits and is designed to provide students with a brief overview of the tools used in data science. Given this, there is no reason to overly complicate a project that accounts for only 20% of the total grade.


I am not sure where you obtained the goal from. But as stated in the course webpage

This practical course will teach students to use popular tools for sourcing data, transforming it, analyzing it, communicating these as visual stories, and deploying them in production. Pre-requisites: Python, HTML, JavaScript, Excel, data science basics

So I believe the Project is aligned with the course goals.



 22f3002811:

A balanced evaluation should aim to assess students’ understanding of the concepts taught, not overwhelm them with disproportionately difficult requirements.


Since I am neither a student nor a faculty/instructor/TA, I clearly see two parts to this argument:
From a teacher’s point of view the student should be provided with meaningful challenges so that learning is both sustainable and transferable. And this means that there are inherent hardships involved in the process. They will aim for the balance by ensuring there are enough opportunities for students to learn in the course. Especially in a course like TDS, this means lot more of hands on activities and assessments as there is very little to teach as concept here.
Here is Anand’s version of this
From a students point of view, there should be something tangible that they can learn which can be used for their career (doesn’t matter what path is chosen) and also optimizes their time and effort .
Note: I think this is a fair expectation from the student and am not dismissing it entirely.
So when it comes to course like TDS, you will be looking at a fairly doable set of assignments and activities that do not eat into your other courses or activities.
So the point becomes, how do you define balanced? Here are some pointers from my side (While these are put in a question format, both instructors and students can adapt these questions in their own context and try to see if these are answered to the best of their abilities)

Are the assessments assessing the intended skills?
Is there clarity on the way the assessment is going to be implemented/administered?
Is there a/multiple mechanisms for student to seek support and clarification both before and during the assessment?
Are the students being nudged to plan and do the assessments?

I hope you can use this as self-check for yourselves to see if these are getting answered satisfactorily.
Now, if you still feel that grading system is not fair, happy to get on a call and discuss this.

[Source](https://discourse.onlinedegree.iitm.ac.in/t/concerns-regarding-unfair-grading-practices-for-tds-project-2/160611/12)

---

**22f3002811** on 2024-12-27:

look man I don’t want to argue but let me make it very simple for you , I don’t have any problem with discussion , clarity or goal of the project , as a matter of fact I like challenges , I enjoyed this course more that any other course in this diploma but there is time for fun and there is a time for Marks .
Now comes the only part where the main issue lies …
image1889×986 101 KB
this is a screen shot of the final result of the final evaluation script ,
Now take a close look at the fields these were the exact evaluation fields which were hidden for final evaluation which determined (ruined) my final score .
Now just tell me how did the LLM evaluated my readme file such that it could not determine what headings my readme contained
image1116×838 77.4 KB
Or how did it figured out that the charts I used are not relevant
,you can see my full response in tds-project2/goodreads at main · AdityaGuptaVarshney/tds-project2 · GitHub
Now To explore alternative evaluation methods
if peer review had been used, I believe it is reasonable to estimate that my final score would have ranged between 80-90%. This aligns with the initial evaluation script, which scored my submission at 89% (14/14).
(Even you basic evaluation script which by the way used llm to give a final grade evaluated my script 89 percent ) ,

(14/14 to be exact)  because of which most of the students including me were confused and thought that they have cracked the project and would get a decent grade … this was the transparency error
Now finally tell me how can you justify it


How can you justify the transformation of 89 % (basic but still relevant) score to a mere (41%) after the final evaluation (which is not working as intended hence the consistency and integrity error)


How can you justify 41 % when with peer review i could have got 90 % easily


How can you justify the degradation of our final grade point from (B to C ) .


Proposed Solutions:

Reevaluate all submissions using a new and fair evaluation script (though I understand this might not be feasible at this stage).
Implement a peer review system to provide more accurate and balanced grading.
Accept the initial test results (14/14 scores) as the final results. While this may be a basic measure, it is at least consistent and reflective of the criteria we optimized our scripts for.

What cannot be done, however, is ignoring the evident flaws in the evaluation system. Students invested weeks optimizing their scripts (from scores like 4/14 to 14/14) based on the visible tests, only to be blindsided by a system that ultimately did not function as intended.
While I am not opposed to new evaluation systems or changes, it is essential that such systems work transparently and consistently to ensure fairness for all students.
Thank you for your time and consideration. I look forward to your response.
Sincerely,
Aditya Gupta

[Source](https://discourse.onlinedegree.iitm.ac.in/t/concerns-regarding-unfair-grading-practices-for-tds-project-2/160611/13)

---

**23f2004790** on 2024-12-27:

I agree with what he has mentioned and in addition I would like to propose a grant of atleast 5 bonus marks to the students who attempted both the projects. This will appreciate the efforts & mental stress they went through to make these projects which ultimately ended up getting inappropriately evaluated by the TDS team.

[Source](https://discourse.onlinedegree.iitm.ac.in/t/concerns-regarding-unfair-grading-practices-for-tds-project-2/160611/14)