# # # app/engine/llm.py

# import os
# import requests
# from dotenv import load_dotenv

# load_dotenv()  # Load variables from .env

# AIPROXY_URL = "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions"
# AIPROXY_TOKEN = os.getenv("AIPROXY_TOKEN")  # Read from .env


# # load_dotenv()
# # AIPROXY_TOKEN = os.getenv("AIPROXY_TOKEN")  # Move this after load
# # print("âœ… AIPROXY_TOKEN:", AIPROXY_TOKEN)



# # def ask_llm(system_prompt: str, user_prompt: str) -> str:
# #     if not AIPROXY_TOKEN:
# #         raise EnvironmentError("Missing AIPROXY_TOKEN in .env")

# #     headers = {
# #         "Content-Type": "application/json",
# #         "Authorization": f"Bearer {AIPROXY_TOKEN}"
# #     }

# #     payload = {
# #         "model": "gpt-4o-mini",
# #         "messages": [
# #             {"role": "system", "content": system_prompt},
# #             {"role": "user", "content": user_prompt}
# #         ]
# #     }

# #     response = requests.post(AIPROXY_URL, headers=headers, json=payload)
# #     response.raise_for_status()
# #     return response.json()["choices"][0]["message"]["content"]
# def ask_llm(system_prompt: str, user_prompt: str) -> str:
#     if not AIPROXY_TOKEN:
#         raise EnvironmentError("Missing AIPROXY_TOKEN in .env")

#     headers = {
#         "Content-Type": "application/json",
#         "Authorization": f"Bearer {AIPROXY_TOKEN}"
#     }

#     payload = {
#         "model": "gpt-4o-mini",
#         "messages": [
#             {"role": "system", "content": system_prompt},
#             {"role": "user", "content": user_prompt}
#         ]
#     }

#     response = requests.post(AIPROXY_URL, headers=headers, json=payload)

#     try:
#         response.raise_for_status()
#         data = response.json()
#         # Debug log
#         print("ğŸ” LLM response JSON:", data)

#         return data["choices"][0]["message"]["content"]
#     except requests.exceptions.HTTPError as e:
#         print("âŒ HTTP Error:", e)
#         print("ğŸ” Response content:", response.text)
#         raise
#     except KeyError as e:
#         print("âŒ Unexpected response structure:", response.json())
#         raise ValueError(f"Unexpected LLM response structure: missing {e}")

import os
import requests

from dotenv import load_dotenv
load_dotenv(dotenv_path=".env", override=True)  # Force reload


AIPROXY_URL = "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions"
AIPROXY_TOKEN = os.getenv("OPENAI_API_KEY")


# def ask_llm(system_prompt: str, user_prompt: str) -> str:
#     if not AIPROXY_TOKEN:
#         raise EnvironmentError("âŒ Missing AIPROXY_TOKEN in .env")

#     headers = {
#         "Content-Type": "application/json",
#         "Authorization": f"Bearer {AIPROXY_TOKEN}"
#     }

#     payload = {
#         "model": "gpt-4o-mini",
#         "messages": [
#             {"role": "system", "content": system_prompt},
#             {"role": "user", "content": user_prompt}
#         ]
#     }

#     print("ğŸ“¤ Sending to AI Proxy:", payload)

#     response = requests.post(AIPROXY_URL, headers=headers, json=payload)

#     try:
#         response.raise_for_status()
#         data = response.json()
#         print("âœ… LLM raw response:", data)
#         print("âœ… AIPROXY_TOKEN found:", bool(AIPROXY_TOKEN))
#         return data["choices"][0]["message"]["content"]
#     except Exception as e:
#         print("âŒ LLM Error:", e)
#         print("âŒ Full response text:", response.text)
        # raise
def ask_llm(system_prompt: str, user_prompt: str) -> str:
    if not AIPROXY_TOKEN:
        raise EnvironmentError("âŒ Missing OPENAI_API_KEY in .env")

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {AIPROXY_TOKEN}"
    }

    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    }

    response = requests.post(AIPROXY_URL, headers=headers, json=payload)

    try:
        response.raise_for_status()
        data = response.json()

        # âœ… Minimal but useful feedback
        content = data["choices"][0]["message"]["content"]
        cost = data.get("cost")
        if cost is not None:
            print(f"âœ… LLM responded successfully. ğŸ’° Cost: ${cost:.6f}")
        else:
            print("âœ… LLM responded successfully.")

        return content

    except requests.exceptions.HTTPError as e:
        print("âŒ HTTP Error:", e)
        print("ğŸ” Response content:", response.text)
        raise
    except KeyError as e:
        print("âŒ Unexpected response structure. Missing key:", e)
        print("ğŸ” Full response:", response.json())
        raise